{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Data Wrangling and Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will install all the necessary drivers and import libraries and modules to organize the project better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#install psql \"driver\" and squarify\n",
    "!pip3 install psycopg2-binary\n",
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from PSQL into DataFrame\n",
    "\n",
    "**Setup Docker Containers**\n",
    "\n",
    "![](https://i.imgur.com/VQrBVBk.jpg)\n",
    "\n",
    "\n",
    "We will use docker to establish a connection between our two containers `jrvs-jupyter` and `jrvs-psql` so we can load the `retail` database into our project. The code below will allow us to create and connect to the network so the two containers can communicate with each other.\n",
    "\n",
    "```\n",
    "# Ensure that you have both jupyter and psql containers up and running\n",
    "docker ps\n",
    "\n",
    "# Attach a bridge network to both containers so they can communicate with each other\n",
    "docker network create jrvs-net\n",
    "# On the running containers connect them to the jrvs-net network\n",
    "docker network connect jrvs-net jrvs-jupyter\n",
    "docker network connect jrvs-net jrvs-psql\n",
    "\n",
    "# Verify that both of the containers are connected to the jrvs-net\n",
    "docker network inspect jrvs-net\n",
    "```\n",
    "\n",
    "**Data Preperation**\n",
    "\n",
    "- Use [pandas.read_sql](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html) api to load the PSQL retail table into a Pandas DataFrame\n",
    "\n",
    "<!-- ![](https://i.imgur.com/AmkAP63.jpg) -->\n",
    "\n",
    "- Get familiar with the transaction date with `df.head()`, `df.sample(10)`, `df.info()`, `df.describe()`, etc..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_string = \"postgresql+psycopg2://postgres:password@jrvs-psql:5432/postgres\"\n",
    "engine = create_engine(engine_string)\n",
    "retail_df = pd.read_sql_table('retail', engine)\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.shape # dimension of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info()\n",
    "retail_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV into Dataframe\n",
    "Alternatively, the LGS IT team also dumped the transactional data into a [CSV file](https://raw.githubusercontent.com/jarviscanada/jarvis_data_eng_demo/feature/data/python_data_wrangling/data/online_retail_II.csv). However, the CSV header (column names) doesn't follow the snakecase or camelcase naming convention (e.g. `Customer ID` instead of `customer_id` or `CustomerID`). As a result, you will need to use Pandas to clean up the data before doing any analytics. In addition, unlike the PSQL scheme, CSV files do not have data types associated. Therefore, you will need to cast/convert certain columns into correct data types (e.g. DateTime, numbers, etc..)\n",
    "\n",
    "**Data Preperation**\n",
    "\n",
    "- Read the `data/online_retail_II.csv` file into a DataFrame\n",
    "- Rename all columns to upper camelcase or snakecase\n",
    "- Convert/cast all columns to the appropriate data types (e.g. datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = pd.read_csv('data/online_retail_II.csv')\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns into snakecase\n",
    "retail_df.rename(columns={'Invoice': 'invoice_no', 'StockCode': 'stock_code', 'Description': 'description',\n",
    "                          'Quantity': 'quantity', 'InvoiceDate': 'invoice_date', 'Price': 'unit_price',\n",
    "                          'Customer ID': 'customer_id', 'Country': 'country'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the `invoice_date` series/column/field (and for row it is tuple/row/record) data type to datetime\n",
    "retail_df['invoice_date'] = pd.to_datetime(retail_df['invoice_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Invoice Amount Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook, we will compute the following:\n",
    "1. Invoice amount\n",
    "2. Draw the distribution of invoice amount with min, max, median, mod, and mean.\n",
    "3. Draw the distribution for the first 85 quantiles of the invoice.\n",
    "\n",
    "Recall, that the invoice amount or the total price is `quantity * unit_price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the invoice amount/total price by using the formula\n",
    "retail_df['invoice_amount'] = retail_df['quantity'] * retail_df['unit_price']\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_amount_df = retail_df.groupby('invoice_no').agg({'invoice_amount': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all negative invoice amounts\n",
    "invoice_amount_df = invoice_amount_df[invoice_amount_df['invoice_amount'] > 0]\n",
    "invoice_amount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that we can re-use\n",
    "def show_distribution(var_data):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    # Get statistics\n",
    "    min_val = var_data.min()\n",
    "    max_val = var_data.max()\n",
    "    mean_val = var_data.mean()\n",
    "    med_val = var_data.median()\n",
    "    mod_val = var_data.mode()[0]\n",
    "\n",
    "    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
    "                                                                                            mean_val,\n",
    "                                                                                            med_val,\n",
    "                                                                                            mod_val,\n",
    "                                                                                            max_val))\n",
    "\n",
    "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
    "\n",
    "    # Plot the histogram   \n",
    "    ax[0].hist(var_data)\n",
    "    ax[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Add lines for the mean, median, and mode\n",
    "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    # Plot the boxplot   \n",
    "    ax[1].boxplot(var_data, vert=False)\n",
    "    ax[1].set_xlabel('Value')\n",
    "\n",
    "    # Add a title to the Figure\n",
    "    fig.suptitle('Data Distribution')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_distribution(invoice_amount_df['invoice_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = invoice_amount_df.quantile(0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers = invoice_amount_df[invoice_amount_df['invoice_amount'] < threshold[0]]\n",
    "remove_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_distribution(remove_outliers['invoice_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Placed and Canceled Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the monthly placed and cancelled orders but before we dive into the code and diagrams we must establish the conditions and assumptions we will be making in this section of the notebook.\n",
    "1. To simplify the problem, we will assume that there are two invoice numbers for each canceled order (one for the original invoice and one for the canceled invoice). Therefore, `# of placed orders = total # of orders - 2 * canceled order`. Furthermore, you can also assume the original invoice and canceled invoice are on always on the same day (this eliminate the case where the original invoice and canceled invoices are on different months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df['yyyymm'] = retail_df['invoice_date'].dt.year * 100 + retail_df['invoice_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info() # check the data type of yyyymm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of orders for each months = placed orders + 2 * cancelled orders\n",
    "total_orders=retail_df.groupby('yyyymm').size()\n",
    "total_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of cancelled orders for each yyyymm groups\n",
    "cancelled_orders = retail_df[retail_df.invoice_no.str.contains('C')].shape\n",
    "cancelled_orders # we have 19494 cancelled orders throughout the entire history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to figure out how many cancelled we have in each month \n",
    "cancelled_orders = retail_df[retail_df.invoice_no.str.contains('C')].groupby('yyyymm').size()\n",
    "cancelled_orders.head() # sums up to 19494 cancelled total orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us verify that we have 1015 cancelled orders in 2009 12\n",
    "check = retail_df[retail_df.invoice_no.str.contains('C')]\n",
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[check.yyyymm == 200912].shape # this confirms that there are 1015 cancelled orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placed_orders = total_orders - 2*cancelled_orders\n",
    "placed_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([cancelled_orders, placed_orders], axis = 1)\n",
    "new_df.rename(columns={0: 'cancelled_orders', 1: 'placed_orders'},inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.plot(kind='bar', figsize=(15,10), xlabel=\"InvoiceYearMonth\", ylabel=\"# of Orders\",\n",
    "            title=\"Monthly Placed and Cancelled Orders\");\n",
    "plt.legend([\"Cancellation\", \"Placement\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed to calculate the monthly sales and plot a diagram to easily read the analysis on the monthly sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales=retail_df.groupby('yyyymm').agg({'invoice_amount': 'sum'})\n",
    "monthly_sales.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the yyyymm column to a string data type for plotting purposes\n",
    "monthly_sales['yyyymm'] = monthly_sales.yyyymm.astype(str)\n",
    "monthly_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,10)}) # Change the size of the diagram to 15x10\n",
    "ax=sns.lineplot(x='yyyymm',y='invoice_amount',data = monthly_sales, label = 'Monthly Sales')\n",
    "plt.legend(['Sales']);\n",
    "plt.xticks(rotation='vertical');\n",
    "ax.set(xlabel='Year-Month', ylabel='Sales (Million)', title='Monthly Sales');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Sales Growth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook, we will determine the monthly sales growth in percentage and plot a chart to see the growth in visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the monthly sales growth we can perform the following opeartions to achieve the results. `Current Month Sales - Previous Month Sales) / Previous Month Sales = Monthly Sales Growth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales['growth'] = monthly_sales.invoice_amount - monthly_sales.invoice_amount.shift(1)\n",
    "monthly_sales.growth = monthly_sales.growth/monthly_sales.invoice_amount.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.lineplot(x='yyyymm',y='growth',data = monthly_sales, label = 'Monthly Sales')\n",
    "plt.legend(['Sales Growth']);\n",
    "plt.xticks(rotation='vertical');\n",
    "ax.set(xlabel='Year-Month', ylabel='Growth %', title='Monthly Sales Growth');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Active Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed to compute the number of active users, i.e. unique customer IDs, for each month and plot a bar chart to display visually how many active users there were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users = retail_df.groupby('yyyymm').nunique('customer_id')[['customer_id']]\n",
    "active_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users.plot(kind='bar', xlabel='Year Month', ylabel='# of Active Users', title='Monthly Active Users')\n",
    "plt.legend(['# of Active Users']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New and Existing Users\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the Jupyter Notebook we will compute and plot the new and existing users in the database. First, we want to explicitly define what new and existing users precisely mean.\n",
    "1. A user is identified as a new user when he/she makes the first purchase.\n",
    "2. A user is identified as an existing user when he/she made purchases in the past.\n",
    "3. We will plot a diagram to show new and exiting user for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the customer's first purchase year and month\n",
    "new = retail_df.groupby(['customer_id']).agg({'yyyymm': 'min'})\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each `customer_id` with the minimum year-month is equal to current year-month of interest then they are new user.\n",
    "\n",
    "If each `customer_id` with the minimum year-month is after (or greater) than the current year-month of interest then they are existing user.\n",
    "\n",
    "It is **very important to note that**, the existing users are all the unique customers in year-month - the new users in the year-month. This simplifies the computation and calculations we have to perform to figure out all the existing users in each year-month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_existing_users = active_users # active_users from calculating monthly active users\n",
    "new_existing_users.rename(columns={'customer_id': 'all_unique_users'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of new customers for each year-month\n",
    "new_users = new.value_counts().sort_index()\n",
    "new_existing_users['new_users'] = new_users.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_existing_users['existing_users'] = new_existing_users.all_unique_users - new_existing_users.new_users\n",
    "new_existing_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_existing_users.plot(kind='bar', xlabel='Invoice Year-Month', ylabel='# of Users',\n",
    "                        title='Number of New and Existing Users')\n",
    "plt.legend([\"All Users\", \"New Users\", \"Existing Users\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding RFM\n",
    "\n",
    "In this section of the Jupyter Notebook, we will compute the RFM values which stands for Recency, Frequency, and Monetary value. Simply put, RFM is a method used for analyzing customer value. It is commonly used in database marketing and direct marketing and has received particular attention in the retail and professional services industries. ([wikipedia](https://en.wikipedia.org/wiki/RFM_(market_research)))\n",
    "\n",
    "RFM stands for three dimensions:\n",
    "\n",
    "- Recency – How recently did the customer purchase?\n",
    "\n",
    "- Frequency – How often do they purchase?\n",
    "\n",
    "- Monetary Value – How much do they spend?\n",
    "\n",
    "To simplify the problem, we will keep all placed and canceled orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.to_datetime('today')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monetary value\n",
    "df_x = retail_df.groupby('customer_id').agg({'invoice_amount': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency value\n",
    "df_y = retail_df.groupby('customer_id').agg({'invoice_date': 'max'})\n",
    "df_y['invoice_date'] = (today - df_y['invoice_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency value is total number of purchases, i.e. finding the frequency value per capita\n",
    "df_z1 = retail_df.groupby(['customer_id', 'invoice_no']).agg({'invoice_amount': 'sum'})\n",
    "df_z = df_z1.groupby('customer_id').agg({'invoice_amount': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RFM table\n",
    "rfm_table= pd.merge(df_x, df_z, on='customer_id')\n",
    "rfm_table = pd.merge(rfm_table, df_y, on='customer_id')\n",
    "#determination of column names\n",
    "rfm_table.rename(columns= {'invoice_date': 'Recency',\n",
    "                          'invoice_amount_y': 'Frequency',\n",
    "                          'invoice_amount_x': 'Monetary'}, inplace= True)\n",
    "rfm_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM score values \n",
    "rfm_table['RecencyScore'] = pd.qcut(rfm_table['Recency'],5,labels=[5,4,3,2,1])\n",
    "rfm_table['FrequencyScore'] = pd.qcut(rfm_table['Frequency'].rank(method=\"first\"),5,labels=[1,2,3,4,5])\n",
    "rfm_table['MonetaryScore'] = pd.qcut(rfm_table['Monetary'],5,labels=[1,2,3,4,5])\n",
    "rfm_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the RFM score column into the RFM table\n",
    "rfm_table[\"RFM_SCORE\"] = rfm_table['RecencyScore'].astype(str) + rfm_table['FrequencyScore'].astype(str) + rfm_table['MonetaryScore'].astype(str)\n",
    "rfm_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFM Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to finalizing the project by performing RFM segmentation which categorizes your customers into different segments, according to their interactions with your website, which will allow you to subsequently approach these groups in the most effective way. In this article, we will show you how to make an RFM segmentation based on an RFM score combining all three RFM parameters together and allowing you to divide your customers into 11 different segments.\n",
    "\n",
    "- [RFM Segmentation business cases](https://docs.exponea.com/docs/rfm-segmentation-business-use)\n",
    "\n",
    "- [RFM Segmentation Guide](https://docs.exponea.com/docs/rfm-segmentation-business-use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting of customers according to RecencyScore and FrequencyScore values\n",
    "seg_map = {\n",
    "    r'[1-2][1-2]': 'Hibernating',\n",
    "    r'[1-2][3-4]': 'At Risk',\n",
    "    r'[1-2]5': 'Can\\'t Lose',\n",
    "    r'3[1-2]': 'About to Sleep',\n",
    "    r'33': 'Need Attention',\n",
    "    r'[3-4][4-5]': 'Loyal Customers',\n",
    "    r'41': 'Promising',\n",
    "    r'51': 'New Customers',\n",
    "    r'[4-5][2-3]': 'Potential Loyalists',\n",
    "    r'5[4-5]': 'Champions'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(seg_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the segment column in the RFM table\n",
    "rfm_table['Segment'] = rfm_table['RecencyScore'].astype(str) + rfm_table['FrequencyScore'].astype(str)\n",
    "rfm_table['Segment'] = rfm_table['Segment'].replace(seg_map, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_level_agg=rfm_table[[\"Segment\", \"Recency\",\"Frequency\",\n",
    "                         \"Monetary\"]].groupby(\"Segment\").agg({'Recency':'mean',\n",
    "                                                              'Frequency': 'mean',\n",
    "                                                              'Monetary':[\"mean\",\"count\"]})\n",
    "rfm_level_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_level_agg.columns = rfm_level_agg.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean','Count']\n",
    "rfm_level_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot and resize it accordingly\n",
    "fig = plt.gcf()\n",
    "ax = fig.add_subplot()\n",
    "fig.set_size_inches(16, 9)\n",
    "squarify.plot(sizes=rfm_level_agg['Count'], \n",
    "              label=labels, alpha=.6 )\n",
    "plt.title(\"Frequency and Recency Grid\",fontsize=16,fontweight=\"bold\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
